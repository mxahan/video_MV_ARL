{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "972f2740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import os\n",
    "#os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "#os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "import torch \n",
    "\n",
    "import pickle \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "\n",
    "import  time\n",
    "import glob\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import random\n",
    "from random import seed, randint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from imutils.video import FPS\n",
    "\n",
    "import imutils\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from threading import Thread\n",
    "import sys\n",
    "\n",
    "from queue import Queue\n",
    "\n",
    "from imutils.video import FileVideoStream\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import pytorchvideo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1080aa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% if necessary\n",
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81590e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Prepare Data Loader ???\n",
    "\n",
    "import importlib\n",
    "import data_set_loader\n",
    "importlib.reload(data_set_loader)\n",
    "from data_set_loader import data_set_Prep\n",
    "from data_set_loader import brightness_augment, snp_RGB, test_data\n",
    "\n",
    "#%% \n",
    "import losses_PT\n",
    "importlib.reload(losses_PT)\n",
    "\n",
    "optimizer = torch.optim.Adam(my_net.parameters(), lr=1e-4)\n",
    "\n",
    "from losses_PT import TripletLoss1, InfoNceLoss, NT_Xent, InfoNCE, align_uniform\n",
    "L= InfoNceLoss(0.5)\n",
    "\n",
    "tan_m =  nn.Tanh()\n",
    "\n",
    "\n",
    "# model_name = \"slowfast_r50\"\n",
    "# model = torch.hub.load(\"facebookresearch/pytorchvideo\", model=model_name, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be04ff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_deterministic(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.enabled = False\n",
    "\n",
    "set_deterministic(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74314994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Data Directory\n",
    "\n",
    "def get_files(path_dir = '../Data/Pickle_files'):\n",
    "    dataPath = os.path.join(path_dir, '*.pkl')\n",
    "    return glob.glob(dataPath)  # care about the serialization\n",
    "\n",
    "\n",
    "files = get_files(path_dir = '../Data/Pickle_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0bf79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Only when required to change the data-source\n",
    "files[0:8], files[8:16] = files[8:16], files[0:8]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9733ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Dataset Loader (final format)\n",
    "import pickle\n",
    "\n",
    "def data_set_loader(files):\n",
    "    temp, dataSet, concat_dataset, data_loader = [], [], [], []\n",
    "\n",
    "    import pdb\n",
    "\n",
    "    for i in range(8):\n",
    "\n",
    "        with open(files[i], 'rb') as f:\n",
    "            temp.append(pickle.load(f))\n",
    "\n",
    "        dataSet.append(data_set_Prep(temp[i], mode_no = 2, samp_siz= 16))\n",
    "        \n",
    "    concat_dataset = torch.utils.data.ConcatDataset(dataSet)\n",
    "    data_loader = DataLoader(concat_dataset, batch_size=1, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    \n",
    "    return data_loader\n",
    "\n",
    "data_loader = []\n",
    "del(data_loader)\n",
    "data_loader = data_set_loader(files[0:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98981e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp[1][2].dtype\n",
    "# resizing videos \n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import (\n",
    "    RandomCrop,\n",
    "    RandomResizedCrop,\n",
    ")\n",
    "\n",
    "\n",
    "class ReSizeVid():\n",
    "    def __init__(self, size = (256, 256)):\n",
    "        self.size = size\n",
    "    \n",
    "    def __call__(self, t_v):\n",
    "        ll =  t_v.shape\n",
    "        kk = torch.empty((ll[0], ll[1], ll[2], ll[3], self.size[0], self.size[1]))\n",
    "        for i in range(ll[1]):\n",
    "            kk[:, i,:,:,:,:] =  self.resize(t_v[0,i], self.size)\n",
    "        return kk\n",
    "    \n",
    "    def resize(self, clip, target_size, interpolation_mode =  \"bilinear\"):\n",
    "        assert len(target_size) == 2, \"target size should be tuple (height, width)\"\n",
    "        return torch.nn.functional.interpolate(\n",
    "            clip, size=target_size, mode=interpolation_mode\n",
    "        )\n",
    "\n",
    "trx = transforms.Compose([ReSizeVid((160, 160))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c00fc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% loading pretrain weight for the P3D199\n",
    "\n",
    "def load_wt(net, pretrained_file='p3d_rgb_199.checkpoint.pth.tar'):\n",
    "    weights=torch.load(pretrained_file)\n",
    "    net.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4b3f73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from p3D_net import P3D131, P3D199, P3D63\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "#%% Input Model name\n",
    "def get_model():\n",
    "    ModName = input(\"Input your model name C3D, P3D199, P3D63, P3D131 \\n\")\n",
    "\n",
    "    def str_to_class(ModelName):\n",
    "        return getattr(sys.modules[__name__], ModelName)\n",
    "\n",
    "    ModelName = str_to_class(ModName)\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    if ModName == 'C3D':\n",
    "        net = ModelName()\n",
    "        net.load_state_dict(torch.load('../../Saved_models/c3d.pickle'))\n",
    "        net = net.cuda()\n",
    "        input_shape = (3,16,112,112)\n",
    "        print(summary(net, input_shape))\n",
    "\n",
    "    elif ModName == 'P3D199':\n",
    "        net = ModelName(False, 'RGB',num_classes=400)\n",
    "        net = net.cuda()\n",
    "        input_shape = (3,16,160,160)\n",
    "        print(summary(net, input_shape))\n",
    "\n",
    "    elif ModName == 'P3D63' or ModName == 'P3D131':\n",
    "        net = ModelName(num_classes=400)\n",
    "#         net.to(device)\n",
    "#         input_shape = (3,16,160,160)\n",
    "#         print(summary(net, input_shape))\n",
    "        \n",
    "    return net \n",
    "\n",
    "    #more network here!!\n",
    "    #SLOWFAST\n",
    "class L2Norm(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x / x.norm(p=2, dim=1, keepdim=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803e5d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "def get_R_model(num_classes = 100, mlp = 0): # single layer only can add many layers if wanted\n",
    "\n",
    "    net = get_model()\n",
    "    # forced layer removal\n",
    "    dim_layer = 2048\n",
    "    net.fc =torch.nn.Linear(in_features=dim_layer, out_features= dim_layer)\n",
    "    \n",
    "    if mlp: \n",
    "        my_net = torch.nn.Sequential(net, nn.ReLU(), nn.Linear(dim_layer, num_classes), L2Norm() )\n",
    "        \n",
    "    else:\n",
    "        net.fc =torch.nn.Linear(in_features=2048, out_features= num_classes)\n",
    "        my_net = torch.nn.Sequential(net, nn.ReLU())\n",
    "    return my_net\n",
    "    \n",
    "    \n",
    "my_net = get_R_model(10, mlp = 0)\n",
    "my_net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3312a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_net(): ## Delete network \n",
    "    del(my_net)\n",
    "    torch.cuda.empty_cache()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8837b169",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "#%% SimCLR Alternate training loop from dataloader\n",
    "#%% https://kozodoi.me/python/deep%20learning/pytorch/tutorial/2021/02/19/gradient-accumulation.html\n",
    "\n",
    "\n",
    "L= NT_Xent(batch_size=5, temperature=0.05, world_size=1)\n",
    "\n",
    "def simCLR_training(criterion, my_net, data_loader, lr= 0.5e-3):\n",
    "    optimizer = torch.optim.SGD(my_net.parameters(), lr= lr) # very relevant params\n",
    "    L= criterion.cuda()\n",
    "    # tdc =  test_data(temp)\n",
    "    j = 0\n",
    "    my_net.train()\n",
    "    for s1,s2 in data_loader: \n",
    "        s1, s2 =  trx(s1), trx(s2)\n",
    "        s1, s2 =  s1[0].cuda(), s2[0].cuda()\n",
    "        o1, o2 = my_net(s1),  my_net(s2)\n",
    "        loss1 = L(o1, o2)\n",
    "        loss1.backward()\n",
    "        optimizer.step() \n",
    "   \n",
    "        if j%500==0:\n",
    "            print(loss1.cpu())\n",
    "            # pdb.set_trace()\n",
    "        j= j+1\n",
    "        optimizer.zero_grad()   # zero the gradient buffers\n",
    "    \n",
    "\n",
    "simCLR_training(L, my_net, data_loader, lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e11514",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Uniform - Alignment loss\n",
    "\n",
    "import pdb\n",
    "def al_un_training(criterion, my_net, data_loader, lr= 0.5e-3, lw =[0.9, 0.1]):\n",
    "    optimizer = torch.optim.SGD(my_net.parameters(), lr= lr) # very relevant params\n",
    "    L= criterion.cuda()\n",
    "    # tdc =  test_data(temp)\n",
    "    j = 0\n",
    "    my_net.train()\n",
    "    for s1,s2 in data_loader: \n",
    "        s1, s2 =  trx(s1), trx(s2)\n",
    "        s1, s2 =  s1[0].cuda(), s2[0].cuda()\n",
    "        o1, o2 = my_net(s1),  my_net(s2)\n",
    "        align_loss_val = align_uniform.align_loss(o1,o2)\n",
    "        uniform_loss_val1 = align_uniform.uniform_loss(o1, t = 2)\n",
    "        uniform_loss_val2 = align_uniform.uniform_loss(o2, t = 2)\n",
    "\n",
    "        loss1 = lw[0]*align_loss_val + lw[1]*uniform_loss_val1 + lw[1]*uniform_loss_val2\n",
    "        \n",
    "        loss1.backward()\n",
    "        optimizer.step() \n",
    "        optimizer.zero_grad()   # zero the gradient buffers\n",
    "#         pdb.set_trace()\n",
    "        if j%500==0:\n",
    "            print(loss1.cpu())\n",
    "            # pdb.set_trace()\n",
    "        j= j+1\n",
    "        \n",
    "    \n",
    "\n",
    "al_un_training(L, my_net, data_loader, lr = 2e-3, lw =[10, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c0a4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% InfoNCE Alternate training loop from dataloader\n",
    "L= InfoNCE(temperature=0.05)\n",
    "# tdc =  test_data(temp)\n",
    "\n",
    "\n",
    "def infoNCE_training(criterion, my_net, data_loader, lr= 0.5e-3, bs  =1):\n",
    "    j = 0\n",
    "    optimizer = torch.optim.SGD(my_net.parameters(), lr= lr) # very relevant params\n",
    "    L = criterion.cuda()\n",
    "    my_net.train()\n",
    "    for s1 in data_loader: \n",
    "        s1 =  trx(s1)\n",
    "        s1 =  s1[0].cuda()\n",
    "        output = my_net(s1)\n",
    "        loss1 = L(output[0:1], output[1:2], output[2:])\n",
    "        \n",
    "        loss1 =  loss1/bs\n",
    "        loss1.backward()\n",
    "        \n",
    "        if ((j+1)%bs == 0) or (j+1 ==len(data_loader)):\n",
    "            optimizer.step() \n",
    "            optimizer.zero_grad()   # zero the gradient buffers\n",
    "            \n",
    "            \n",
    "        if j%500==0:\n",
    "            print(loss1.cpu()*bs)\n",
    "            # pdb.set_trace()\n",
    "        j= j+1\n",
    "        \n",
    "        \n",
    "for _ in range(1):\n",
    "    infoNCE_training(L, my_net, data_loader, lr = 1e-3, bs =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38e2fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn\n",
    "with torch.no_grad():\n",
    "    ot = my_net(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7427368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../Data/Pickle_files/nirandi_8_26_21_300_300.pkl'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ba04e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "with open(files[7], 'rb') as f:\n",
    "            temp.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f3ff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#%% Preparing test dataset (change for every new dataset)\n",
    "# test result\n",
    "# a = np.int16([0, 1650 , 3240, 4530, 6240,7980,9180,10980, 11580,12030])\n",
    "\n",
    "def embed_test(td, a, my_net):\n",
    "    data_t =[]\n",
    "    data_lab = []\n",
    "\n",
    "    my_net.eval()\n",
    "    for i in range(a.shape[0]-2):\n",
    "        for _ in range(100):\n",
    "            sample = torch.from_numpy(td.get_data_test(randint(a[i], a[i+1])))\n",
    "            sample = trx(sample[None, :])[0]\n",
    "            sample = sample.cuda()\n",
    "            with torch.no_grad():\n",
    "                output = my_net(sample)\n",
    "            data_t.append(output.cpu().numpy())\n",
    "            data_lab.append([i,i,i])\n",
    "\n",
    "\n",
    "    data_t = np.array(data_t)\n",
    "    data_lab = np.int16(data_lab)\n",
    "    h,w,l = data_t.shape\n",
    "    data_t = data_t.reshape((h*w,l))\n",
    "    data_lab = data_lab.reshape((h*w,1))\n",
    "    \n",
    "    return data_t, data_lab, h, w\n",
    "\n",
    "td = test_data(temp[0], frm_no=16)\n",
    "\n",
    "a = np.int16([0, 27*30 , 58*30, 80*30, 110*30, 150*30, 175*30, 227*30, 257*30,325*30, 355*30])\n",
    "named_labe =  ['sitting', 'standing', 'walking', 'Lying up', 'lying down', 'Obj inter', 'push up', 'leg move', 'hand wave, stand', 'what']\n",
    "\n",
    "\n",
    "data_t, data_lab, h, w = embed_test(td, a, my_net)\n",
    "\n",
    "# rmsev=  data_t/np.sqrt(np.sum(data_t**2, axis = 1))[:, np.newaxis] # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b256673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def tsne_plot(data = data_t, n_comp = 2, label1 = label3, Lol = None, LoL = 1):\n",
    "    if Lol== None:\n",
    "        X_embedded = TSNE(n_components=n_comp, verbose=1).fit_transform(data)\n",
    "    else:\n",
    "        X_embedded = LoL\n",
    "            \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot()\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    if n_comp == 3:ax = fig.add_subplot(projection ='3d')\n",
    "    \n",
    "    # cdict = {0: 'red', 1: 'blue', 2: 'green'}\n",
    "    \n",
    "    markers = ['v', 'x', 'o', '.', '>', '<', '1', '2', '3']\n",
    "    \n",
    "    for i, g in enumerate(np.unique(label1)):\n",
    "        ix = np.where(label1 == g)\n",
    "        if n_comp==3:\n",
    "            ax.scatter(X_embedded[ix,0], X_embedded[ix,1], X_embedded[ix,2], marker = markers[i], label = g, alpha = 0.8)\n",
    "        else:\n",
    "            ax.scatter(X_embedded[ix,0], X_embedded[ix,1], marker = markers[i], label = g, alpha = 0.8)\n",
    "    \n",
    "    ax.set_xlabel('X Label')\n",
    "    ax.set_ylabel('Y Label')\n",
    "    if n_comp==3:ax.set_zlabel('Z Label')\n",
    "    if n_comp==3:ax.set_zlabel('Z Label')\n",
    "\n",
    "    ax.legend(fontsize='large', markerscale=2); plt.show()\n",
    "    ax.legend(fontsize='large', markerscale=2); plt.show()\n",
    "    #plt 2\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot()\n",
    "    if n_comp == 3:ax = fig.add_subplot(projection ='3d')\n",
    "    \n",
    "    # cdict = {0: 'red', 1: 'blue', 2: 'green'}\n",
    "    markers = ['v', 'x', 'x', '.', '>', '<', '1', '2', '3', '4']\n",
    "    for i, g in enumerate([3,2]):# enumerate(np.unique(data_lab)):\n",
    "        ix = np.where(data_lab == g)\n",
    "        if n_comp==3:\n",
    "            ax.scatter(X_embedded[ix,0], X_embedded[ix,1], X_embedded[ix,2], marker = markers[i], label = g, alpha = 0.8)\n",
    "        else:\n",
    "            ax.scatter(X_embedded[ix,0], X_embedded[ix,1], marker = markers[i], label = named_labe[g], alpha = 0.8)\n",
    "    ax.set_xlabel('X Label')\n",
    "    ax.set_ylabel('Y Label')\n",
    "    ax.legend(fontsize='large', markerscale=2, bbox_to_anchor=(0.5, .5, 1.2, 0.5))\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "label3 = np.reshape(np.int16([ i for i in range(h*w)])%3, (h*w,1))\n",
    "tsne_plot(data_t, 2, label3, Lol =None,  LoL = 1)\n",
    "\n",
    "# shillohette coefficient! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df16ab0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Model weight save and load\n",
    "\n",
    "torch.save(my_net.state_dict(), '../My_net_p_131_save.pth')\n",
    "\n",
    "load_wt(my_net, pretrained_file='../My_net_p_131_save.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
